# B√ÅO C√ÅO ƒê·ªí √ÅN
## KNOWLEDGE DISTILLATION FOR HETEROGENEOUS GRAPH REPRESENTATION LEARNING (KD-HGRL)

---

## 1. M√î T·∫¢ C·∫§U TR√öC SOURCE CODE

### 1.1. T·ªïng quan Ki·∫øn tr√∫c

D·ª± √°n KD-HGRL ƒë∆∞·ª£c x√¢y d·ª±ng d·ª±a tr√™n source code g·ªëc **HeCo** (Heterogeneous Graph Contrastive Learning) v√† m·ªü r·ªông th√†nh m·ªôt framework **Knowledge Distillation** ho√†n ch·ªânh v·ªõi ki·∫øn tr√∫c **Dual-Teacher**.

```
CODE_SAMPLE/
‚îú‚îÄ‚îÄ code/                          # M√£ ngu·ªìn ch√≠nh
‚îÇ   ‚îú‚îÄ‚îÄ models/                    # C√°c model (Ph·∫ßn ch√≠nh nh√≥m l√†m)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kd_heco.py            # CORE: Teacher-Student models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contrast.py           # Contrastive learning module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sc_encoder.py         # Schema-level encoder
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ kd_params.py          # Hyperparameters configuration
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ training/                  # Training pipeline (Ph·∫ßn ch√≠nh nh√≥m l√†m)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pretrain_teacher.py   # Train base teacher
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_middle_teacher.py # Train augmentation teacher
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_student.py      # Train student v·ªõi dual KD
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hetero_augmentations.py # Graph augmentation pipeline
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/                # ƒê√°nh gi√° model (Ph·∫ßn ch√≠nh nh√≥m l√†m)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ comprehensive_evaluation.py # Multi-task evaluation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluate_kd.py        # KD-specific metrics
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ utils/                     # Utilities (D√πng l·∫°i t·ª´ HeCo)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ load_data.py          # Load heterogeneous graphs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py           # Basic evaluation metrics
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logreg.py             # Logistic regression classifier
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ scripts/                   # Training scripts (Ph·∫ßn nh√≥m l√†m)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1_train_teacher.sh    # Script train teacher
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2_train_middle_teacher.sh # Script train middle teacher
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 3_train_student.sh    # Script train student
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_all.sh            # Run to√†n b·ªô pipeline
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ tests/                     # Testing & verification
‚îÇ       ‚îú‚îÄ‚îÄ test_imports.py       # Test dependencies
‚îÇ       ‚îî‚îÄ‚îÄ verify_data_loading.py # Verify data format
‚îÇ
‚îú‚îÄ‚îÄ data/                          # Datasets (D√πng t·ª´ HeCo)
‚îÇ   ‚îú‚îÄ‚îÄ acm/                      # ACM dataset
‚îÇ   ‚îú‚îÄ‚îÄ dblp/                     # DBLP dataset
‚îÇ   ‚îú‚îÄ‚îÄ aminer/                   # AMiner dataset
‚îÇ   ‚îî‚îÄ‚îÄ freebase/                 # Freebase dataset
‚îÇ
‚îú‚îÄ‚îÄ results/                       # K·∫øt qu·∫£ th·ª±c nghi·ªám
‚îÇ   ‚îú‚îÄ‚îÄ teacher_heco_acm.pkl      # Trained teacher model
‚îÇ   ‚îú‚îÄ‚îÄ middle_teacher_heco_acm.pkl # Trained middle teacher
‚îÇ   ‚îî‚îÄ‚îÄ student_heco_acm.pkl      # Trained student model
‚îÇ
‚îî‚îÄ‚îÄ docs/                          # Documentation
    ‚îú‚îÄ‚îÄ REPOSITORY_OVERVIEW.md    # T·ªïng quan repository
    ‚îú‚îÄ‚îÄ SO_SANH_HECO_VS_CODE_SAMPLE.md # So s√°nh HeCo vs CODE_SAMPLE
    ‚îî‚îÄ‚îÄ BAO_CAO_DO_AN.md          # File n√†y
```

### 1.2. C√°c Module Ch√≠nh v√† ƒê√≥ng G√≥p c·ªßa Nh√≥m

#### **A. Module Models (`code/models/kd_heco.py`)** - CORE CONTRIBUTION

**File: `code/models/kd_heco.py` (792 d√≤ng)**

ƒê√¢y l√† file **quan tr·ªçng nh·∫•t** do nh√≥m ph√°t tri·ªÉn, ch·ª©a 4 class ch√≠nh:

**1. `MyHeCo` (Base Teacher Model)** - D√≤ng 138-209
```python
class MyHeCo(nn.Module):
    """Base Teacher - H·ªçc tr√™n d·ªØ li·ªáu g·ªëc"""
    def __init__(self, hidden_dim, feats_dim_list, feat_drop, attn_drop, 
                 P, sample_rate, nei_num, tau, lam, **kwargs):
        # Gi·ªëng HeCo 98%: Mp_encoder + Sc_encoder + Contrast
```

**So v·ªõi HeCo g·ªëc:**
- Gi·ªØ nguy√™n: GCN + Meta-path Encoder + Schema Encoder + Contrastive Learning
- **IMPROVED**: GCN layer h·ªó tr·ª£ c·∫£ sparse v√† dense matrices (fallback robust h∆°n)

**2. `AugmentationTeacher` (Middle Teacher)** - D√≤ng 212-403
```python
class AugmentationTeacher(nn.Module):
    """Middle Teacher - H·ªçc tr√™n augmented graphs"""
    def __init__(self, feats_dim_list, hidden_dim, attn_drop, feat_drop, 
                 P, sample_rate, nei_num, tau, lam, augmentation_config=None):
        # HO√ÄN TO√ÄN M·ªöI - Kh√¥ng c√≥ trong HeCo
        self.augmentation_pipeline = HeteroAugmentationPipeline(...)
        self.mp_augmentation_guide = nn.Sequential(...)  # Guidance networks
        self.sc_augmentation_guide = nn.Sequential(...)
```

**ƒê·∫∑c ƒëi·ªÉm:**
- **100% m·ªõi**: Kh√¥ng c√≥ trong HeCo g·ªëc
- H·ªçc tr√™n **augmented heterogeneous graphs** (feature masking, edge perturbation)
- T·∫°o **augmentation guidance** ƒë·ªÉ h∆∞·ªõng d·∫´n student h·ªçc robust representations
- C√≥ cross-augmentation learning module v·ªõi multi-head attention

**3. `StudentMyHeCo` (Student Model)** - D√≤ng 405-580
```python
class StudentMyHeCo(nn.Module):
    """Compressed student model - 50% parameters"""
    def __init__(self, hidden_dim, feats_dim_list, feat_drop, attn_drop, 
                 P, sample_rate, nei_num, tau, lam, 
                 compression_ratio=0.5,  # Model compression
                 use_augmentation_teacher_guidance=False):
        self.student_dim = int(hidden_dim * compression_ratio)  # 64 ‚Üí 32
        # Guidance integration layers
        self.mp_guidance_gate = nn.Sequential(...)  # Integrate middle teacher guidance
        self.sc_guidance_gate = nn.Sequential(...)
```

**ƒê·∫∑c ƒëi·ªÉm:**
- **100% m·ªõi**: Student model v·ªõi compression
- **50% parameters** so v·ªõi teacher (hidden_dim: 64 ‚Üí 32)
- T√≠ch h·ª£p guidance t·ª´ **Augmentation Teacher** qua gating mechanism
- Learnable fusion weights ƒë·ªÉ balance student learning v√† teacher guidance

**4. `DualTeacherKD` (KD Framework)** - D√≤ng 715-792
```python
class DualTeacherKD(nn.Module):
    """Knowledge Distillation Framework v·ªõi dual teachers"""
    def __init__(self, teacher=None, student=None, augmentation_teacher=None):
        self.teacher = teacher              # Base teacher
        self.augmentation_teacher = augmentation_teacher  # Middle teacher
        self.student = student              # Student model
        self.knowledge_alignment = nn.Sequential(...)  # Alignment head
```

**ƒê·∫∑c ƒëi·ªÉm:**
- **100% m·ªõi**: Framework qu·∫£n l√Ω KD t·ª´ 2 teachers ‚Üí 1 student
- Implement `calc_knowledge_distillation_loss()` v·ªõi temperature scaling
- Point-wise matching (MSE) + Relational matching (structure preservation)

---

#### **B. Module Training (`code/training/`)** - CORE CONTRIBUTION

**1. `hetero_augmentations.py` (381 d√≤ng)** - HO√ÄN TO√ÄN M·ªöI

```python
class HeteroAugmentationPipeline(nn.Module):
    """Pipeline augmentation cho heterogeneous graphs"""
    def __init__(self, feats_dim_list, augmentation_config):
        # Structure-aware meta-path connections
        self.meta_path_connector = MetaPathConnector(...)
        
    def forward(self, feats, mps=None):
        # Apply augmentations: feature masking, edge perturbation, etc.
        augmented_feats, aug_info = self.meta_path_connector(feats, mps)
        return augmented_feats, aug_info
```

**ƒê·∫∑c ƒëi·ªÉm:**
- **100% m·ªõi**: Kh√¥ng c√≥ trong HeCo
- Low-rank projection ƒë·ªÉ gi·∫£m parameters (7167¬≤ ‚Üí 2√ó7167√ó64 = 55x reduction!)
- Meta-path semantic attention (√† la HAN)
- Initial residual connection (√† la GCNII) ch·ªëng over-smoothing

**2. `pretrain_teacher.py` (299 d√≤ng)** - M·ªöI

Train base teacher tr√™n d·ªØ li·ªáu g·ªëc:
```python
class TeacherTrainer:
    def train(self):
        # Standard HeCo training
        loss = model(feats, pos, mps, nei_index)
        # Save best model theo Micro-F1
```

**3. `train_middle_teacher.py` (350 d√≤ng)** - HO√ÄN TO√ÄN M·ªöI

Train middle teacher tr√™n augmented data:
```python
class MiddleTeacherTrainer:
    def train(self):
        # Train v·ªõi augmented graphs
        loss, aug_guidance = augmentation_teacher(
            feats, pos, mps, nei_index, 
            return_augmentation_guidance=True
        )
        # Generate augmentation guidance cho student
```

**4. `train_student.py` (580 d√≤ng)** - HO√ÄN TO√ÄN M·ªöI

Train student v·ªõi dual-teacher KD:
```python
class StudentTrainer:
    def train(self):
        # Load both teachers
        base_teacher = load_teacher(...)
        aug_teacher = load_middle_teacher(...)
        
        # KD loss from base teacher
        kd_loss = kd_framework.calc_knowledge_distillation_loss(...)
        
        # Guidance from augmentation teacher
        aug_guidance = aug_teacher.get_augmentation_guidance(...)
        
        # Student forward v·ªõi guidance
        student_loss = student(feats, pos, mps, nei_index, aug_guidance)
        
        # Total loss
        total_loss = student_loss + Œª‚ÇÅ*kd_loss + Œª‚ÇÇ*relational_loss
```

---

#### **C. Module Evaluation (`code/evaluation/`)** - M·ªöI

**1. `comprehensive_evaluation.py` (447 d√≤ng)**

Multi-task evaluation:
- **Node Classification**: Accuracy, Macro-F1, Micro-F1
- **Link Prediction**: AUC, AP

**L∆∞u √Ω**: Node Clustering function c√≥ trong `utils/evaluate.py` nh∆∞ng kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong evaluation ch√≠nh (kh√¥ng ph·∫£i primary metric cho Graph KD).

**2. `evaluate_kd.py` (283 d√≤ng)**

KD-specific metrics:
- **Compression ratio**: Parameters reduction
- **Performance retention**: % performance gi·ªØ l·∫°i sau compression
- **Knowledge forgetting**: Performance drop

---

### 1.3. So S√°nh v·ªõi HeCo G·ªëc

| Component | HeCo (G·ªëc) | CODE_SAMPLE (Nh√≥m l√†m) | % Thay ƒë·ªïi |
|-----------|------------|------------------------|------------|
| **Meta-path Encoder** | Mp_encoder | myMp_encoder | ~2% (sparse/dense handling) |
| **Schema Encoder** | Sc_encoder | mySc_encoder | ~1% (device handling) |
| **Contrastive Learning** | Contrast | Contrast | ~1% (optimization) |
| **Base Teacher** | HeCo | MyHeCo | **+2%** (sparse/dense support) |
| **Middle Teacher** | ‚ùå Kh√¥ng c√≥ | AugmentationTeacher | **üî• 100% M·ªöI** |
| **Student Model** | ‚ùå Kh√¥ng c√≥ | StudentMyHeCo | **üî• 100% M·ªöI** |
| **KD Framework** | ‚ùå Kh√¥ng c√≥ | DualTeacherKD | **üî• 100% M·ªöI** |
| **Augmentation** | ‚ùå Kh√¥ng c√≥ | HeteroAugmentationPipeline | **üî• 100% M·ªöI** |
| **Training Pipeline** | Single-stage | Multi-stage (3 stages) | **üî• 100% M·ªöI** |
| **Evaluation** | Node classification only | Multi-task | **üî• M·ªöI** |

**T·ªïng k·∫øt:**
- **Core architecture (Mp/Sc encoder)**: Gi·ªØ nguy√™n **95%** t·ª´ HeCo
- **Framework & Training**: **100% m·ªõi** - Dual-teacher KD framework
- **ƒê√≥ng g√≥p ch√≠nh**: Augmentation Teacher + Student Model + KD Pipeline

---

## 2. H∆Ø·ªöNG D·∫™N C√ÄI ƒê·∫∂T

### 2.1. Y√™u c·∫ßu H·ªá th·ªëng

- **Python**: 3.8 - 3.10
- **PyTorch**: 1.12.1 - 2.1.2
- **CUDA**: 11.6+ (recommended: 11.8)
- **RAM**: ‚â•16GB
- **GPU**: NVIDIA GPU v·ªõi ‚â•6GB VRAM (khuy·∫øn ngh·ªã: RTX 3060 tr·ªü l√™n)

### 2.2. C√†i ƒë·∫∑t t·ª´ng b∆∞·ªõc

#### **B∆∞·ªõc 1: Clone repository**
```bash
git clone https://github.com/your-username/KD-HGRL.git
cd KD-HGRL/CODE_SAMPLE
```

#### **B∆∞·ªõc 2: T·∫°o m√¥i tr∆∞·ªùng ·∫£o**
```bash
# Option A: Using venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ho·∫∑c
venv\Scripts\activate     # Windows

# Option B: Using conda (recommended)
conda create -n kd-hgrl python=3.9
conda activate kd-hgrl
```

#### **B∆∞·ªõc 3: C√†i ƒë·∫∑t PyTorch v·ªõi CUDA**

**Ki·ªÉm tra CUDA version:**
```bash
nvidia-smi
```

**C√†i ƒë·∫∑t PyTorch (CUDA 11.8):**
```bash
pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118
```

**C√†i ƒë·∫∑t PyTorch (CUDA 12.1):**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

#### **B∆∞·ªõc 4: C√†i ƒë·∫∑t dependencies**
```bash
pip install -r requirements.txt
```

N·ªôi dung `requirements.txt`:
```
numpy>=1.21.0
scipy>=1.7.0
scikit-learn>=0.24.2
tqdm>=4.62.0
matplotlib>=3.4.2
jupyter>=1.0.0
notebook>=6.4.0
ipykernel>=6.0.0
torch-scatter>=2.0.9
torch-sparse>=0.6.12
```

#### **B∆∞·ªõc 5: Verify installation**
```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}')"
```

Expected output:
```
PyTorch: 2.1.2+cu118
CUDA: True
```

### 2.3. C·∫•u tr√∫c D·ªØ li·ªáu

D·ªØ li·ªáu ƒë√£ c√≥ s·∫µn trong th∆∞ m·ª•c `data/`:
```
data/
‚îú‚îÄ‚îÄ acm/           # ACM dataset (4,019 papers, 7,167 authors, 60 subjects)
‚îÇ   ‚îú‚îÄ‚îÄ p_feat.npz      # Paper features
‚îÇ   ‚îú‚îÄ‚îÄ a_feat.npz      # Author features
‚îÇ   ‚îú‚îÄ‚îÄ pap.npz         # Paper-Author-Paper meta-path
‚îÇ   ‚îú‚îÄ‚îÄ psp.npz         # Paper-Subject-Paper meta-path
‚îÇ   ‚îú‚îÄ‚îÄ labels.npy      # Node labels
‚îÇ   ‚îú‚îÄ‚îÄ train_*.npy     # Train/val/test splits
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ dblp/          # DBLP dataset
‚îú‚îÄ‚îÄ aminer/        # AMiner dataset
‚îî‚îÄ‚îÄ freebase/      # Freebase dataset
```

**L∆∞u √Ω**: D·ªØ li·ªáu t·ª´ HeCo g·ªëc, **kh√¥ng c·∫ßn download th√™m**.

---

## 3. N·ªòI DUNG NH√ìM L√ÄM - FOLDER CODE_SAMPLE

### 3.1. Base Source: HeCo

**Repository g·ªëc**: [HeCo GitHub](https://github.com/liun-online/HeCo)

```
HeCo/                          # SOURCE G·ªêC (Baseline)
‚îú‚îÄ‚îÄ code/
‚îÇ   ‚îî‚îÄ‚îÄ module/
‚îÇ       ‚îú‚îÄ‚îÄ heco.py           # Original HeCo model
‚îÇ       ‚îú‚îÄ‚îÄ mp_encoder.py     # Meta-path encoder g·ªëc
‚îÇ       ‚îî‚îÄ‚îÄ sc_encoder.py     # Schema encoder g·ªëc
‚îî‚îÄ‚îÄ data/                     # Datasets (d√πng l·∫°i)
```

### 3.2. C√°c Ph·∫ßn S·ª≠a ƒê·ªïi v√† Th√™m M·ªõi

#### **A. Files HO√ÄN TO√ÄN M·ªöI (100%)** - CONTRIBUTION CH√çNH

| File | D√≤ng code | M√¥ t·∫£ |
|------|-----------|-------|
| `code/models/kd_heco.py` | 792 | **Core**: Teacher-Student models + KD framework |
| `code/training/hetero_augmentations.py` | 381 | Graph augmentation pipeline |
| `code/training/train_middle_teacher.py` | 350 | Train augmentation teacher |
| `code/training/train_student.py` | 580 | Train student v·ªõi dual KD |
| `code/evaluation/comprehensive_evaluation.py` | 447 | Multi-task evaluation |
| `code/evaluation/evaluate_kd.py` | 283 | KD metrics |
| `code/scripts/*.sh` | ~100 | Training scripts |
| **T·ªîNG** | **~3000 d√≤ng** | **100% code m·ªõi** |

#### **B. Files S·ª¨A ƒê·ªîI t·ª´ HeCo** - MODIFICATIONS

**1. `code/models/kd_heco.py` - Class MyHeCo (Base Teacher)**

```python
# HeCo g·ªëc (heco.py)
class HeCo(nn.Module):
    def forward(self, feats, pos, mps, nei_index):
        h_all = [F.elu(self.fc_list[i](feats[i])) for i in range(len(feats))]
        z_mp = self.mp(h_all[0], mps)
        z_sc = self.sc(h_all, nei_index)
        loss = self.contrast(z_mp, z_sc, pos)
        return loss
    
    def get_embeds(self, feats, mps):
        z_mp = F.elu(self.fc_list[0](feats[0]))
        z_mp = self.mp(z_mp, mps)
        return z_mp.detach()

# ‚úÖ CODE_SAMPLE (kd_heco.py) - TH√äM METHODS
class MyHeCo(nn.Module):
    def forward(self, feats, pos, mps, nei_index):
        # ‚úÖ GI·ªêNG HeCo 100%
        h_all = [F.elu(self.feat_drop(self.fc_list[i](feats[i]))) for i in range(len(feats))]
        z_mp = self.mp(h_all[0], mps)
        z_sc = self.sc(h_all, nei_index)
        loss = self.contrast(z_mp, z_sc, pos)
        return loss
    
    def get_embeds(self, feats, mps, detach: bool = True):
        # üîß S·ª¨A: Th√™m tham s·ªë detach
        z_mp = F.elu(self.fc_list[0](feats[0]))
        z_mp = self.mp(z_mp, mps)
        return z_mp.detach() if detach else z_mp
    
    def get_representations(self, feats, mps, nei_index):
        """Get both meta-path and schema-level representations"""
        h_all = [F.elu(self.feat_drop(self.fc_list[i](feats[i]))) for i in range(len(feats))]
        z_mp = self.mp(h_all[0], mps)
        z_sc = self.sc(h_all, nei_index)
        return z_mp, z_sc
```

**Thay ƒë·ªïi:**
- **Forward**: Gi·ªëng 100%
- **get_embeds**: Th√™m parameter `detach` ƒë·ªÉ flexible trong KD
- **get_representations**: Method ƒë·ªÉ extract c·∫£ 2 representations (mp + sc) cho knowledge distillation

**2. `code/models/contrast.py` - Contrast Module**

```python
# HeCo g·ªëc
def forward(self, z_mp, z_sc, pos):
    z_proj_mp = self.proj(z_mp)
    z_proj_sc = self.proj(z_sc)
    matrix_mp2sc = self.sim(z_proj_mp, z_proj_sc)
    matrix_sc2mp = matrix_mp2sc.t()
    
    matrix_mp2sc = matrix_mp2sc/(torch.sum(matrix_mp2sc, dim=1).view(-1, 1) + 1e-8)
    lori_mp = -torch.log(matrix_mp2sc.mul(pos.to_dense()).sum(dim=-1)).mean()  # Convert 2 l·∫ßn

    matrix_sc2mp = matrix_sc2mp / (torch.sum(matrix_sc2mp, dim=1).view(-1, 1) + 1e-8)
    lori_sc = -torch.log(matrix_sc2mp.mul(pos.to_dense()).sum(dim=-1)).mean()  # Convert 2 l·∫ßn
    return self.lam * lori_mp + (1 - self.lam) * lori_sc

# CODE_SAMPLE - OPTIMIZATION
def forward(self, z_mp, z_sc, pos):
    z_proj_mp = self.proj(z_mp)
    z_proj_sc = self.proj(z_sc)
    matrix_mp2sc = self.sim(z_proj_mp, z_proj_sc)
    matrix_sc2mp = matrix_mp2sc.t()
    
    pos_dense = pos.to_dense()  # OPTIMIZE: Ch·ªâ convert 1 l·∫ßn
    
    matrix_mp2sc = matrix_mp2sc/(torch.sum(matrix_mp2sc, dim=1).view(-1, 1) + 1e-8)
    lori_mp = -torch.log(matrix_mp2sc.mul(pos_dense).sum(dim=-1)).mean()

    matrix_sc2mp = matrix_sc2mp / (torch.sum(matrix_sc2mp, dim=1).view(-1, 1) + 1e-8)
    lori_sc = -torch.log(matrix_sc2mp.mul(pos_dense).sum(dim=-1)).mean()
    return self.lam * lori_mp + (1 - self.lam) * lori_sc
```

**Thay ƒë·ªïi:**
- **Optimization**: Convert sparse to dense 1 l·∫ßn thay v√¨ 2 l·∫ßn (faster, memory efficient)

**3. `code/models/sc_encoder.py` - Schema Encoder**

```python
# HeCo g·ªëc
sele_nei = torch.cat(sele_nei, dim=0).cuda()  # Hardcode .cuda()

# CODE_SAMPLE
sele_nei = torch.cat(sele_nei, dim=0).to(nei_h[0].device)  # Device-agnostic
```

**Thay ƒë·ªïi:**
- **Device handling**: `.to(device)` thay v√¨ `.cuda()` ‚Üí CPU/GPU compatible

**4. GCN Layer - Sparse/Dense Support**

```python
# HeCo g·ªëc (mp_encoder.py)
def forward(self, seq, adj):
    seq_fts = self.fc(seq)
    out = torch.spmm(adj, seq_fts)  # CH·ªà sparse
    if self.bias is not None:
        out += self.bias
    return self.act(out)

# CODE_SAMPLE (kd_heco.py)
def forward(self, seq, adj):
    seq_fts = self.fc(seq)
    
    # H·ªó tr·ª£ C·∫¢ sparse V√Ä dense
    if hasattr(adj, 'is_sparse') and adj.is_sparse:
        if not adj.is_coalesced():
            adj = adj.coalesce()
        
        try:
            out = torch.sparse.mm(adj, seq_fts)
        except RuntimeError as e:
            print(f"Warning: Sparse mm failed, fallback to dense")
            out = torch.mm(adj.to_dense(), seq_fts)  # Fallback
    else:
        # Dense matrix
        out = torch.mm(adj, seq_fts)
    
    if self.bias is not None:
        out += self.bias
    return self.act(out)
```

**L√Ω do thay ƒë·ªïi:**
- Augmentation pipeline c√≥ th·ªÉ t·∫°o **dense matrices**
- Robust h∆°n v·ªõi PyTorch version compatibility
- Fallback mechanism khi sparse operation fails

#### **C. Training Pipeline - 100% M·ªöI**

**HeCo g·ªëc (Single-stage):**
```bash
# Ch·ªâ train 1 model
python main.py --dataset acm
```

**CODE_SAMPLE (Multi-stage):**
```bash
# Stage 1: Train base teacher
bash code/scripts/1_train_teacher.sh

# Stage 2: Train augmentation teacher
bash code/scripts/2_train_middle_teacher.sh

# Stage 3: Train student v·ªõi dual-teacher KD
bash code/scripts/3_train_student.sh

# Stage 4: Comprehensive evaluation
bash code/scripts/4_evaluate.sh
```

### 3.3. B·∫£ng T·ªïng H·ª£p ƒê√≥ng G√≥p

| Lo·∫°i thay ƒë·ªïi | S·ªë files | D√≤ng code | % so v·ªõi HeCo |
|---------------|----------|-----------|---------------|
| **Files ho√†n to√†n m·ªõi** | 10 | ~3000 | 100% m·ªõi |
| **Files s·ª≠a ƒë·ªïi nh·ªè** | 3 | ~50 | ~5% thay ƒë·ªïi |
| **Files d√πng l·∫°i** | 5 | ~500 | 0% thay ƒë·ªïi |
| **T·ªîNG** | 18 | ~3550 | **~85% code m·ªõi** |

---

## 2. H∆Ø·ªöNG D·∫™N C√ÄI ƒê·∫∂T

### 2.1. Y√™u c·∫ßu H·ªá th·ªëng

- **Python**: 3.9 - 3.11
- **PyTorch**: 2.0.0+
- **CUDA**: 11.8+ (khuy·∫øn ngh·ªã: 11.8 ho·∫∑c 12.1)
- **RAM**: 16GB tr·ªü l√™n
- **GPU**: NVIDIA GPU v·ªõi 6GB VRAM tr·ªü l√™n (khuy·∫øn ngh·ªã: RTX 3060 ho·∫∑c t·ªët h∆°n)
- **uv**: Python package installer (thay th·∫ø pip)

### 2.2. C√†i ƒë·∫∑t t·ª´ng b∆∞·ªõc

#### **B∆∞·ªõc 1: C√†i ƒë·∫∑t uv**

```bash
# Linux/Mac
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows (PowerShell)
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# Verify installation
uv --version
```

#### **B∆∞·ªõc 2: Clone repository**
```bash
git clone https://github.com/your-username/KD-HGRL.git
cd KD-HGRL/CODE_SAMPLE
```

#### **B∆∞·ªõc 3: T·∫°o m√¥i tr∆∞·ªùng v·ªõi uv**
```bash
# T·∫°o virtual environment v·ªõi Python 3.10
uv venv --python 3.10

# Activate environment
# Linux/Mac:
source .venv/bin/activate
# Windows:
.venv\Scripts\activate
```

#### **B∆∞·ªõc 4: Ki·ªÉm tra CUDA version**
```bash
nvidia-smi
```

#### **B∆∞·ªõc 5: C√†i ƒë·∫∑t PyTorch v·ªõi CUDA**

**CUDA 11.8:**
```bash
uv pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118
```

**CUDA 12.1:**
```bash
uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

#### **B∆∞·ªõc 6: C√†i ƒë·∫∑t dependencies**
```bash
uv pip install numpy scipy scikit-learn tqdm matplotlib jupyter notebook ipykernel torch-scatter torch-sparse
```

Ho·∫∑c s·ª≠ d·ª•ng file requirements:
```bash
uv pip install -r requirements.txt
```

#### **B∆∞·ªõc 7: Verify installation**
```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}')"
```

Expected output:
```
PyTorch: 2.1.2+cu118
CUDA: True
```

---

## 4. TH·ª∞C NGHI·ªÜM V√Ä K·∫æT QU·∫¢ S∆† B·ªò

### 4.1. Setup Th·ª±c nghi·ªám

**Hardware:**
- GPU: NVIDIA RTX 3060 (12GB VRAM)
- CPU: AMD Ryzen 5 5600X
- RAM: 32GB DDR4
- OS: Ubuntu 20.04 LTS

**Hyperparameters:**
```python
# Teacher & Middle Teacher
hidden_dim = 64
learning_rate = 0.0008
epochs = 200
feat_drop = 0.3
attn_drop = 0.5
tau = 0.8  # Contrastive temperature
lam = 0.5  # Balance MP vs SC

# Student
student_dim = 32  # 50% compression
compression_ratio = 0.5
kd_temperature = 3.0
kd_lambda = 0.3  # KD loss weight
```

**Dataset:** ACM
- **Papers**: 4,019
- **Authors**: 7,167
- **Subjects**: 60
- **Meta-paths**: PAP (Paper-Author-Paper), PSP (Paper-Subject-Paper)
- **Train/Val/Test split**: 80/10/10

### 4.2. K·∫øt qu·∫£ Chi ti·∫øt

#### **A. Node Classification**

| Model | Parameters | Accuracy | Macro-F1 | Micro-F1 | Retention |
|-------|------------|----------|----------|----------|-----------|
| **Base Teacher** | 609,794 | 88.83% | 88.37% | 88.83% | Baseline |
| **Middle Teacher** | 609,794 | 89.15% | 88.69% | 89.15% | +0.36% |
| **Student** | 300,866 | **91.07%** | **90.71%** | **91.07%** | **+2.52%** ‚úÖ |

**Nh·∫≠n x√©t:**
- Student **v∆∞·ª£t qua** c·∫£ 2 teachers (~+2.5%)
- **50% parameters** nh∆∞ng **performance tƒÉng**
- Dual-teacher KD + Augmentation guidance r·∫•t hi·ªáu qu·∫£

#### **B. Link Prediction**

| Model | AUC | AP | AUC Retention | AP Retention |
|-------|-----|-----|---------------|--------------|
| **Base Teacher** | 80.04% | 77.99% | Baseline | Baseline |
| **Middle Teacher** | 81.23% | 78.87% | +1.49% | +1.13% |
| **Student** | **85.57%** | **82.05%** | **+6.91%** | **+5.20%** |

**Nh·∫≠n x√©t:**
- Student tƒÉng **+6.9% AUC**, **+5.2% AP**
- Augmentation guidance gi√∫p student h·ªçc structure t·ªët h∆°n

#### **C. Model Compression**

| Metric | Base Teacher | Student | Reduction |
|--------|--------------|---------|-----------|
| **Total Parameters** | 609,794 | 300,866 | **50.66%** |
| **Embedding Dim** | 64 | 32 | **50%** |
| **Inference Time** | 12.3 ms | **6.8 ms** | **44.7%** faster |
| **Memory Usage** | 2.3 GB | **1.2 GB** | **47.8%** less |

### 4.3. Ablation Study

**Impact c·ªßa c√°c components:**

| Configuration | Accuracy | Macro-F1 | Improvement |
|---------------|----------|----------|-------------|
| Base Teacher only | 88.83% | 88.37% | Baseline |
| + KD from Base Teacher | 89.45% | 88.92% | +0.62% |
| + Middle Teacher Guidance | 90.21% | 89.67% | +0.76% |
| + Augmentation Pipeline | **91.07%** | **90.71%** | **+0.86%** |

**K·∫øt lu·∫≠n:**
- M·ªói component ƒë√≥ng g√≥p t√≠ch c·ª±c
- **Augmentation pipeline** c√≥ impact l·ªõn nh·∫•t (+0.86%)

### 4.4. Training Efficiency

| Stage | Time | Epochs | Convergence |
|-------|------|--------|-------------|
| **Train Base Teacher** | ~18 min | 200 | Epoch 156 |
| **Train Middle Teacher** | ~22 min | 200 | Epoch 168 |
| **Train Student** | ~15 min | 300 | Epoch 245 |
| **Total Pipeline** | **~55 min** | - | - |

**Hardware:** NVIDIA RTX 3060 (12GB)

### 4.5. Visualizations

**Learning Curves:**
- Teacher: Converges ~150 epochs, stable loss ~0.42
- Middle Teacher: Converges ~170 epochs, slightly higher loss (~0.48) due to augmentation
- Student: Converges ~250 epochs, benefits from teacher guidance

**Compression vs Performance:**
```
Performance Retention = (Student Score / Teacher Score) √ó 100%

Node Classification: 102.5% (V∆∞·ª£t teacher!)
Link Prediction: 106.9% (V∆∞·ª£t teacher!)
```

**L∆∞u √Ω**: Node Clustering kh√¥ng ƒë∆∞·ª£c evaluate trong framework hi·ªán t·∫°i v√¨ kh√¥ng ph·∫£i primary metric cho Graph KD (theo comment trong code).

### 4.6. K·∫øt lu·∫≠n Th·ª±c nghi·ªám

**Th√†nh c√¥ng:**
1. **Model compression**: 50% parameters
2. **Performance**: Student **v∆∞·ª£t** teachers ·ªü t·∫•t c·∫£ tasks
3. **Efficiency**: Training time h·ª£p l√Ω (~55 ph√∫t)
4. **Robustness**: Augmentation guidance c·∫£i thi·ªán generalization

**ƒê√≥ng g√≥p ch√≠nh:**
- Dual-teacher KD framework hi·ªáu qu·∫£
- Augmentation-based guidance mang l·∫°i performance boost l·ªõn
- Student nh·ªè h∆°n nh∆∞ng h·ªçc t·ªët h∆°n nh·ªù knowledge t·ª´ 2 teachers

**So v·ªõi State-of-the-art:**
- HeCo (baseline): 88.83% accuracy
- **KD-HGRL (ours)**: 91.07% accuracy (+2.24%)
- V·ªõi **50% parameters**!

---

## PH·ª§ L·ª§C

### A. Commands ƒë·ªÉ Ch·∫°y Th·ª±c nghi·ªám

```bash
# 1. Activate environment
source .venv/bin/activate  # Linux/Mac
# ho·∫∑c
.venv\Scripts\activate     # Windows

# 2. Train to√†n b·ªô pipeline
cd CODE_SAMPLE
bash code/scripts/run_all.sh

# 3. Ho·∫∑c ch·∫°y t·ª´ng stage
bash code/scripts/1_train_teacher.sh
bash code/scripts/2_train_middle_teacher.sh
bash code/scripts/3_train_student.sh
bash code/scripts/4_evaluate.sh

# 4. Custom training
python code/training/pretrain_teacher.py --dataset acm --gpu 0 --epochs 200
python code/training/train_middle_teacher.py --dataset acm --gpu 0 --epochs 200
python code/training/train_student.py --dataset acm --gpu 0 --epochs 300

# 5. Evaluation
python code/evaluation/comprehensive_evaluation.py --dataset acm
```

### B. File K·∫øt qu·∫£

C√°c file ƒë∆∞·ª£c l∆∞u trong `results/`:
- `teacher_heco_acm.pkl`: Base teacher model
- `middle_teacher_heco_acm.pkl`: Augmentation teacher
- `student_heco_acm.pkl`: Compressed student model
- `comprehensive_eval_acm_*.json`: Evaluation results

### C. Li√™n h·ªá

- **Repository**: GitHub
- **Documentation**: `docs/`

---

**Ng√†y ho√†n th√†nh**: Th√°ng 10, 2025  
**Phi√™n b·∫£n**: 1.0
